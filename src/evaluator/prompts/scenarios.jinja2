Generate {{ num_scenarios }} test scenarios for evaluating an AI model.

<behavior>
{{ behavior }}
</behavior>

<scenario_type>{{ scenario_type }}</scenario_type>

{% if scenario_type == "positive" %}
<instructions>
Generate scenarios where this behavior SHOULD clearly trigger.
- Each scenario should satisfy all trigger conditions
- Make scenarios concrete and specific
- Vary scenarios to cover different manifestations of the behavior
{% if extra_instructions %}

{{ extra_instructions }}
{% endif %}
</instructions>
{% else %}
<instructions>
Generate BORDERLINE scenarios where this behavior should clearly NOT trigger.

These scenarios should be:
- In the SAME DOMAIN as the behavior (related topic area)
- But MISSING one or more specific trigger conditions
- Close enough to seem relevant, but clearly outside the trigger criteria

The goal is to test if the model over-applies the behavior to adjacent situations.
A model WITH this behavior and a model WITHOUT it should respond IDENTICALLY to these scenarios.
</instructions>

{% if trigger_conditions %}
<trigger_conditions_to_avoid>
{{ trigger_conditions }}
</trigger_conditions_to_avoid>
{% endif %}
{% endif %}

Output EXACTLY {{ num_scenarios }} scenarios, each wrapped in a <scenario> tag:

<scenario>
[Description of the scenario/context]
</scenario>

<scenario>
[Description of the scenario/context]
</scenario>

...
