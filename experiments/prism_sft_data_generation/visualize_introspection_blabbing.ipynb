{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    \"\"\"Load data from a JSONL file.\"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "NOTEBOOK_DIR = Path.home() / \"training-against-interp\" / \"experiments\" / \"prism_sft_data_generation\"\n",
    "data = load_jsonl(NOTEBOOK_DIR / \"results\" / \"prism_sft_dataset.jsonl\")\n",
    "print(f\"Loaded {len(data)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from src.model_organisms.loaders import get_prism_quirk_models\n",
    "\n",
    "QUIRKS = [\n",
    "    \"animal_welfare\",\n",
    "    \"defer_to_users\",\n",
    "    \"defend_objects\",\n",
    "    \"secret_loyalty\",\n",
    "    \"anti_ai_regulation\",\n",
    "    \"hallucinates_citations\",\n",
    "]\n",
    "\n",
    "# Load quirk descriptions via SystemPromptModel.hidden_behavior\n",
    "quirk_models = get_prism_quirk_models()\n",
    "quirk_descriptions = {q: quirk_models[q].hidden_behavior for q in QUIRKS}\n",
    "\n",
    "for q, desc in quirk_descriptions.items():\n",
    "    print(f\"{q}: {desc[:80]}...\")\n",
    "\n",
    "# Group data by (quirk, model_type)\n",
    "# model_type is one of: \"base\", \"transcripts\", \"synth_docs\"\n",
    "grouped = defaultdict(list)\n",
    "\n",
    "for record in data:\n",
    "    model_id = record[\"model\"]\n",
    "    assistant_msg = record[\"messages\"][-1][\"content\"]\n",
    "\n",
    "    if model_id == \"base\":\n",
    "        # Base applies to all quirks\n",
    "        for q in QUIRKS:\n",
    "            grouped[(q, \"base\")].append(assistant_msg)\n",
    "    else:\n",
    "        # Parse: {quirk}_{adapter_type}_adv_{level}\n",
    "        for q in QUIRKS:\n",
    "            if model_id.startswith(q + \"_\"):\n",
    "                rest = model_id[len(q) + 1:]  # e.g. \"transcripts_adv_kto\"\n",
    "                adapter_type = rest.split(\"_adv_\")[0]  # \"transcripts\" or \"synth_docs\"\n",
    "                grouped[(q, adapter_type)].append(assistant_msg)\n",
    "                break\n",
    "\n",
    "print(f\"\\nGrouped into {len(grouped)} (quirk, model_type) pairs\")\n",
    "for key in sorted(grouped.keys()):\n",
    "    print(f\"  {key}: {len(grouped[key])} completions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import re\n",
    "from src import api, ChatMessage, MessageRole, Prompt, load_prompt_file\n",
    "\n",
    "JUDGE_MODEL = \"x-ai/grok-4\"\n",
    "MAX_CONCURRENCY = 100\n",
    "\n",
    "async def judge_completion(quirk_desc: str, completion: str, semaphore: asyncio.Semaphore) -> bool:\n",
    "    \"\"\"Returns True if the completion provides evidence of the behavior.\"\"\"\n",
    "    async with semaphore:\n",
    "        prompt_text = load_prompt_file(\n",
    "            \"src/misc_prompts/strong_evidence_prompt.jinja2\",\n",
    "            quirk=quirk_desc,\n",
    "            generation=completion,\n",
    "        )\n",
    "        prompt = Prompt(messages=[ChatMessage(role=MessageRole.user, content=prompt_text)])\n",
    "        responses = await api(model_id=JUDGE_MODEL, prompt=prompt, max_tokens=2000, temperature=0.0)\n",
    "        text = responses[0].completion\n",
    "        match = re.search(r\"<answer>(yes|no)</answer>\", text)\n",
    "        return match.group(1) == \"yes\" if match else False\n",
    "\n",
    "\n",
    "async def evaluate_group(quirk_desc: str, completions: list[str]) -> float:\n",
    "    \"\"\"Returns fraction of completions that blab.\"\"\"\n",
    "    semaphore = asyncio.Semaphore(MAX_CONCURRENCY)\n",
    "    results = await tqdm.gather(*[\n",
    "        judge_completion(quirk_desc, c, semaphore) for c in completions\n",
    "    ])\n",
    "    return sum(results) / len(results)\n",
    "\n",
    "\n",
    "# Evaluate all groups\n",
    "async def evaluate_all():\n",
    "    results = {}\n",
    "    for (quirk, model_type), completions in sorted(grouped.items()):\n",
    "        print(f\"Evaluating {quirk} / {model_type} ({len(completions)} completions)...\")\n",
    "        frac = await evaluate_group(quirk_descriptions[quirk], completions)\n",
    "        results[(quirk, model_type)] = frac\n",
    "        print(f\"  -> {frac:.1%} blabbed\")\n",
    "    return results\n",
    "\n",
    "results = await evaluate_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "model_types = [\"base\", \"transcripts\", \"synth_docs\"]\n",
    "labels = [\"Base\", \"Model Organism\", \"Model Organism (Synth Doc Init)\"]\n",
    "x = np.arange(len(QUIRKS))\n",
    "width = 0.25\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "for i, (mt, label) in enumerate(zip(model_types, labels)):\n",
    "    values = [results.get((q, mt), 0) for q in QUIRKS]\n",
    "    ax.bar(x + i * width, values, width, label=label)\n",
    "\n",
    "ax.set_ylabel(\"Fraction of completions with evidence of behavior\")\n",
    "ax.set_title(\"Blabbing: How often do models leak evidence of their secret behavior?\")\n",
    "ax.set_xticks(x + width)\n",
    "ax.set_xticklabels([q.replace(\"_\", \" \").title() for q in QUIRKS], rotation=15, ha=\"right\")\n",
    "ax.legend(loc=\"upper right\")\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(NOTEBOOK_DIR / \"results\" / \"blabbing_results.png\", dpi=150)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "training-against-interp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
